{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification: Language Detection\n",
    "\n",
    "Authors: Pierre Nugues and Marcus Klang"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this programming assignment, you will design and train a classifier to predict the language of a text. More concretely, you will reimplement Google's _Compact language detector_ (CLD3) from a high-level description. Read the description here: https://github.com/google/cld3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your classifier will read a short text, typically a few words or a sentence, and output the probability for all languages observed during training. The text will have a variable length and will be encoded as a Unicode string.\n",
    "\n",
    "As dataset to train your models, you will use [Tatoeba](https://tatoeba.org/sv/), a collaborative, open, and free collection of sentences and translations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will break down the task into four steps:\n",
    "    \n",
    "  1. Data processing, converting the data into a machine-learnable representation\n",
    "  2. Try and evaluate a simple model, logistic regression. This will be your baseline.\n",
    "  3. Try and evaluate a deeper model inspired by Google's compact language detector, CLD3.\n",
    "  4. CLD3 includes an embedding vectorization. This last part is left as an optional exercise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Model: CLD3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CLD3 has three major characteristics:\n",
    "\n",
    "   * It uses **$n$-grams** and splits an input text like _banana_ into three feature vectors that include:\n",
    "       + Each unique character, unigrams ($n=1$)\n",
    "       + Each unique pair of characters obtained from a sliding window of size 2, bigrams ($n=2$)\n",
    "       + Each unique triple of characters obtained from a sliding window of size 3, trigrams ($n=3$)\n",
    "       + These feature sets map to a set of indices (integer value).\n",
    "   \n",
    "   * It **hashes each symbol** i.e. it encrypts the $n$-gram into a fixed range integer.\n",
    "       + This way of mapping features to indices is called feature hashing or the *hashing trick*\n",
    "       + It reduces the number of symbols.\n",
    "       + Constant memory requirements, depends on the hash function -- commonly only a few constants.\n",
    "       + It is an approximate method as collisions can and will occur. Adjusting the size of the feature space i.e. the number of features to hash to, the collision probability can be reduced.\n",
    "   \n",
    "   * For each value of $n$, 1, 2, and 3, CLD3 computes the relative frequencies of the $n$-grams and **use them as weights**. See the figure below.\n",
    "       + The model can map the input indices to embedding vectors (this part is optional)\n",
    "       + It then computes the **weighted average** of the embeddings (this part is optional)\n",
    "       + The model learns the embeddings during training (also optional)\n",
    "       \n",
    "The figure below shows the final architecture."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Model overview](https://raw.githubusercontent.com/google/cld3/master/model.png)\n",
    "Image source: https://github.com/google/cld3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset: Tatoeba"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your instructors have downsampled Tatoeba to reduce training times and guarantee that all the students have the same datasets.\n",
    "* Link to datasets: https://github.com/pnugues/edan96/tree/main/classification%20lab\n",
    "* Link to preprocessing notebook: https://github.com/pnugues/edan96/blob/main/programs/5-tatoeba_eda_select.ipynb\n",
    "\n",
    "You are only required to process the small dataset. The larger one may take take and be difficult to process on small computers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preliminaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import hashlib\n",
    "from collections import Counter\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uncomment these lines the first time run the notebook to download the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!wget https://github.com/pnugues/edan96/raw/main/classification%20lab/small_dataset.zip\n",
    "#!wget https://github.com/pnugues/edan96/raw/main/classification%20lab/large_dataset.zip\n",
    "#!unzip -o small_dataset.zip\n",
    "#!unzip -o large_dataset.zip\n",
    "import urllib.request\n",
    "\n",
    "urllib.request.urlretrieve(\n",
    "    \"https://github.com/pnugues/edan96/raw/main/classification%20lab/small_dataset.zip\",\n",
    "    \"small_dataset.zip\"\n",
    ")\n",
    "\n",
    "urllib.request.urlretrieve(\n",
    "    \"https://github.com/pnugues/edan96/raw/main/classification%20lab/large_dataset.zip\",\n",
    "    \"large_dataset.zip\"\n",
    ")\n",
    "import zipfile\n",
    "\n",
    "with zipfile.ZipFile(\"small_dataset.zip\", 'r') as z:\n",
    "    z.extractall(\".\")\n",
    "\n",
    "with zipfile.ZipFile(\"large_dataset.zip\", 'r') as z:\n",
    "    z.extractall(\".\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x1a9a97b3c30>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.seed(4321)\n",
    "torch.manual_seed(4321)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "FILENAME_TRAIN = 'train.tsv'\n",
    "FILENAME_VAL = 'val.tsv'\n",
    "FILENAME_TEST = 'test.tsv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "SMALL_DATASET_PATH = 'small_dataset'\n",
    "LARGE_DATASET_PATH = 'large_dataset'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Settings\n",
    "You have here the most significant settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "LARGE_DATASET = False # Use the small or large dataset\n",
    "REL_FREQ = True # How we represent the n-grams in the input vector: with their relative frequency or with a 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "#HIDDEN_LAYER = True\n",
    "HIDDEN_LAYER = True  # Neural network with one hidden layer or logistic regression\n",
    "HIDDEN_DIM = 512 # Number of hidden dimensions of the neural network\n",
    "EPOCHS = 10 # Number of epochs\n",
    "BATCH_SIZE = 32 # How many examples we will use for an update in the gradient descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "if LARGE_DATASET:\n",
    "    dataset_path = LARGE_DATASET_PATH\n",
    "else:\n",
    "    dataset_path = SMALL_DATASET_PATH\n",
    "    \n",
    "FILE_TRAIN = dataset_path + '/' + FILENAME_TRAIN\n",
    "FILE_VAL = dataset_path + '/' + FILENAME_VAL\n",
    "FILE_TEST = dataset_path + '/' + FILENAME_TEST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create a generator to read the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "def file_reader(file):\n",
    "    with open(file, encoding='utf8', errors='ignore') as f:\n",
    "        for line in f:\n",
    "            row = line.strip()\n",
    "            yield tuple(row.split('\\t'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "line_generator = file_reader(FILE_TRAIN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we count the sentences per language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "lang_freqs = Counter(map(lambda x: x[1], line_generator))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('rus', 886),\n",
       " ('mkd', 876),\n",
       " ('eng', 873),\n",
       " ('lat', 854),\n",
       " ('swc', 847),\n",
       " ('tur', 844),\n",
       " ('tlh', 843),\n",
       " ('hun', 838),\n",
       " ('vie', 832),\n",
       " ('epo', 830),\n",
       " ('jpn', 830),\n",
       " ('nld', 826),\n",
       " ('lfn', 824),\n",
       " ('deu', 821),\n",
       " ('ces', 814)]"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lang_freqs.most_common(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ara', 'ber', 'bul', 'ces', 'cmn', 'dan', 'deu', 'ell', 'eng', 'epo']"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "langs = sorted(list(set(lang_freqs.keys())))\n",
    "langs[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will create an index of the languages of your dataset: Assign a number to each language. You will call it `idx2lang` and its type will be a dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 'ara', 1: 'ber', 2: 'bul', 3: 'ces', 4: 'cmn', 5: 'dan', 6: 'deu', 7: 'ell', 8: 'eng', 9: 'epo', 10: 'fin', 11: 'fra', 12: 'hau', 13: 'heb', 14: 'hun', 15: 'ina', 16: 'ita', 17: 'jpn', 18: 'kab', 19: 'lat', 20: 'lfn', 21: 'lit', 22: 'mar', 23: 'mkd', 24: 'nld', 25: 'pes', 26: 'pol', 27: 'por', 28: 'ron', 29: 'rus', 30: 'spa', 31: 'srp', 32: 'swc', 33: 'swe', 34: 'tlh', 35: 'tok', 36: 'tur', 37: 'ukr', 38: 'vie'}\n"
     ]
    }
   ],
   "source": [
    "# Write your code\n",
    "idx2lang = dict(enumerate(langs))\n",
    "print(idx2lang)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'ara',\n",
       " 1: 'ber',\n",
       " 2: 'bul',\n",
       " 3: 'ces',\n",
       " 4: 'cmn',\n",
       " 5: 'dan',\n",
       " 6: 'deu',\n",
       " 7: 'ell',\n",
       " 8: 'eng',\n",
       " 9: 'epo',\n",
       " 10: 'fin',\n",
       " 11: 'fra',\n",
       " 12: 'hau',\n",
       " 13: 'heb',\n",
       " 14: 'hun',\n",
       " 15: 'ina',\n",
       " 16: 'ita',\n",
       " 17: 'jpn',\n",
       " 18: 'kab',\n",
       " 19: 'lat',\n",
       " 20: 'lfn',\n",
       " 21: 'lit',\n",
       " 22: 'mar',\n",
       " 23: 'mkd',\n",
       " 24: 'nld',\n",
       " 25: 'pes',\n",
       " 26: 'pol',\n",
       " 27: 'por',\n",
       " 28: 'ron',\n",
       " 29: 'rus',\n",
       " 30: 'spa',\n",
       " 31: 'srp',\n",
       " 32: 'swc',\n",
       " 33: 'swe',\n",
       " 34: 'tlh',\n",
       " 35: 'tok',\n",
       " 36: 'tur',\n",
       " 37: 'ukr',\n",
       " 38: 'vie'}"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx2lang"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write the reverted `lang2idx` index to convert languages to indices. It is also a dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code\n",
    "lang2idx = {}\n",
    "for idx, lang in enumerate(langs):\n",
    "    lang2idx[lang] = idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ara': 0,\n",
       " 'ber': 1,\n",
       " 'bul': 2,\n",
       " 'ces': 3,\n",
       " 'cmn': 4,\n",
       " 'dan': 5,\n",
       " 'deu': 6,\n",
       " 'ell': 7,\n",
       " 'eng': 8,\n",
       " 'epo': 9,\n",
       " 'fin': 10,\n",
       " 'fra': 11,\n",
       " 'hau': 12,\n",
       " 'heb': 13,\n",
       " 'hun': 14,\n",
       " 'ina': 15,\n",
       " 'ita': 16,\n",
       " 'jpn': 17,\n",
       " 'kab': 18,\n",
       " 'lat': 19,\n",
       " 'lfn': 20,\n",
       " 'lit': 21,\n",
       " 'mar': 22,\n",
       " 'mkd': 23,\n",
       " 'nld': 24,\n",
       " 'pes': 25,\n",
       " 'pol': 26,\n",
       " 'por': 27,\n",
       " 'ron': 28,\n",
       " 'rus': 29,\n",
       " 'spa': 30,\n",
       " 'srp': 31,\n",
       " 'swc': 32,\n",
       " 'swe': 33,\n",
       " 'tlh': 34,\n",
       " 'tok': 35,\n",
       " 'tur': 36,\n",
       " 'ukr': 37,\n",
       " 'vie': 38}"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lang2idx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data processing — convert the sentences into feature vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the context of this program, a feature is a string of 1 to 3 characters. \n",
    "In natural language processing, they are called $n$-grams as they can have a varying size and are created from a sliding window.\n",
    "\n",
    "Common sizes of $n$ have names unigrams ($n$=1), bigrams ($n$=2), and trigrams ($n$=3))\n",
    "\n",
    "To serve as input, we have to convert these $n$-grams to numbers. There are two common ways to encode features into indices:\n",
    " * Mapping each symbol to an index\n",
    "    + Exact and precise\n",
    "    + Can have high memory requirements with vast feature spaces as each known feature must be stored and be assigned a unique index.\n",
    "    + Slow, you need to precompute your feature space, convert the incoming data to an index and retain the mapping in memory at all times.\n",
    " * Hashing trick: hash the feature into a index\n",
    "    + Supports an arbitrary number of features with the caveat of collisions.\n",
    "    + Constant memory requirements\n",
    "    + Fast, any feature even an unknown one can be converted into a feature index\n",
    "    + However, if the feature space is too small, features will have many collisions. You have then to choose a good hash function and a feature space that is big enough\n",
    "    \n",
    "We will use the [hashing trick](https://en.wikipedia.org/wiki/Feature_hashing). In Python, `hash` is a function that converts any supported object into a number (hash code) but it is not reproducible across the sessions - it changes each time the interpreter is started.\n",
    "We have therefore provided a new function `reproducible_hash` that hashes a string but in a reproducible way.\n",
    "\n",
    "The number returned by `reproducible_hash` is big and needs to be converted into a limited space. This can be done with the use of the remainder of an integer division, the [modulo](https://en.wikipedia.org/wiki/Modulo_operation)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting $n$-grams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create an $n$-gram function that returns the $n$-grams of a string. The $n$ value will be passed as an argument. You will optionally set the string in lower case (`lc` argument)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here\n",
    "def ngrams(sentence, n=1, lc=True):\n",
    "    ngram_l = []\n",
    "    for i in range(len(sentence)-n+1):\n",
    "        gram = sentence[i:i+n]\n",
    "        ngram_l.append(gram)\n",
    "    return ngram_l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "def all_ngrams(sentence, max_ngram=3, lc=True):\n",
    "    all_ngram_list = []\n",
    "    for i in range(1, max_ngram + 1): #for the feature right-open in py\n",
    "        all_ngram_list += [ngrams(sentence, n=i, lc=lc)]\n",
    "    return all_ngram_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['b', 'a', 'n', 'a', 'n', 'a'],\n",
       " ['ba', 'an', 'na', 'an', 'na'],\n",
       " ['ban', 'ana', 'nan', 'ana']]"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_ngrams('banana')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Limiting the $n$-grams numbers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We set the modulos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "if LARGE_DATASET:\n",
    "    MAX_CHARS = 2053\n",
    "    MAX_BIGRAMS = 4099\n",
    "    MAX_TRIGRAMS = 4099  #8192\n",
    "else:\n",
    "    MAX_CHARS = 521\n",
    "    MAX_BIGRAMS = 1031\n",
    "    MAX_TRIGRAMS = 1031 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2583"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NUM_FEATURES = MAX_CHARS + MAX_BIGRAMS + MAX_TRIGRAMS\n",
    "NUM_FEATURES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hash Codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reproducible_hash(string):\n",
    "    \"\"\"\n",
    "    reproducible hash on any string\n",
    "    \n",
    "    Arguments:\n",
    "       string: python string object\n",
    "    \n",
    "    Returns:\n",
    "       signed int64\n",
    "    \"\"\"\n",
    "    \n",
    "    # We are using MD5 for speed not security.\n",
    "    h = hashlib.md5(string.encode(\"utf-8\"), usedforsecurity=False)\n",
    "    return int.from_bytes(h.digest()[0:8], 'big', signed=True)#translate from byte to decimal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[306, 663, 940, 91, 626, 675, 919, 487, 876, 246, 876]"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[reproducible_hash(x) % MAX_TRIGRAMS for x in all_ngrams('i love banana')[2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[521, 1031, 1031]"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MAXES = [MAX_CHARS, MAX_BIGRAMS, MAX_TRIGRAMS]\n",
    "MAXES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a `hash_ngrams` function that creates a list of hash codes from a list of $n$-grams. As arguments, you will have the list of $n$-grams as well as the list of dividers (`MAXES`). See the example below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code\n",
    "def hash_ngrams(ngrams, modulos):\n",
    "    hash_codes = []\n",
    "    for i in range (1,4):\n",
    "        product = [reproducible_hash(x) % MAXES[i-1] for x in ngrams[i-1]]\n",
    "        hash_codes.append(product)\n",
    "    return hash_codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[233, 86, 15, 97, 121, 32, 86, 25, 234, 310, 234, 310, 234],\n",
       " [428, 379, 199, 495, 944, 474, 839, 994, 649, 808, 649, 808],\n",
       " [306, 663, 940, 91, 626, 675, 919, 487, 876, 246, 876]]"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hash_banana = hash_ngrams(all_ngrams('i love banana'), MAXES)\n",
    "hash_banana"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hash codes relative frequencies\n",
    "CLD3 associates the $n$-gram hash codes with their relative frequencies in the text. See the example in Google CLD3 page.\n",
    "\n",
    "Create a `rel_freqs` function that computes the frequencies from a list of hash codes. The input will be one of the three lists of hash codes, for the unigrams, bigrams, and trigrams respectively. The output will be a dictionary, where the keys will be the $n$-gram hash codes and the values, the relative frequency. See example. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code\n",
    "def rel_freqs(lst):\n",
    "    cnt = Counter(lst)\n",
    "    total_count = len(lst)\n",
    "    freq_dict = {k: v/total_count for k, v in cnt.items()}\n",
    "\n",
    "    return freq_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{233: 0.07692307692307693,\n",
       "  86: 0.15384615384615385,\n",
       "  15: 0.07692307692307693,\n",
       "  97: 0.07692307692307693,\n",
       "  121: 0.07692307692307693,\n",
       "  32: 0.07692307692307693,\n",
       "  25: 0.07692307692307693,\n",
       "  234: 0.23076923076923078,\n",
       "  310: 0.15384615384615385},\n",
       " {428: 0.08333333333333333,\n",
       "  379: 0.08333333333333333,\n",
       "  199: 0.08333333333333333,\n",
       "  495: 0.08333333333333333,\n",
       "  944: 0.08333333333333333,\n",
       "  474: 0.08333333333333333,\n",
       "  839: 0.08333333333333333,\n",
       "  994: 0.08333333333333333,\n",
       "  649: 0.16666666666666666,\n",
       "  808: 0.16666666666666666},\n",
       " {306: 0.09090909090909091,\n",
       "  663: 0.09090909090909091,\n",
       "  940: 0.09090909090909091,\n",
       "  91: 0.09090909090909091,\n",
       "  626: 0.09090909090909091,\n",
       "  675: 0.09090909090909091,\n",
       "  919: 0.09090909090909091,\n",
       "  487: 0.09090909090909091,\n",
       "  876: 0.18181818181818182,\n",
       "  246: 0.09090909090909091}]"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freqs_banana = [rel_freqs(x) for x in hash_banana]\n",
    "freqs_banana"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multihot vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a `multihot` function that creates a torch vector of 0.0 and 1.0 from a dictionary of indices and frequencies. You will pass the size of the vector as an argument. All the indices in the dictionary will be set to 1.0 and the rest will be set to 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here\n",
    "def multihot(idx_freq, max):\n",
    "    feat_vector = torch.zeros(max)\n",
    "    for idx in idx_freq.keys():\n",
    "        feat_vector[idx] = 1.0\n",
    "    return feat_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mhot_char_banana = multihot(freqs_banana[0], MAX_CHARS)\n",
    "mhot_char_banana"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 25],\n",
       "        [234],\n",
       "        [310]])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.nonzero(mhot_char_banana)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0.,  ..., 0., 0., 0.])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mhot_bigram_banana = multihot(freqs_banana[1], MAX_BIGRAMS)\n",
    "mhot_bigram_banana"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[649],\n",
       "        [808],\n",
       "        [994]])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.nonzero(mhot_bigram_banana)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0.,  ..., 0., 0., 0.])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mhot_trigram_banana = multihot(freqs_banana[2], MAX_TRIGRAMS)\n",
    "mhot_trigram_banana"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[246],\n",
       "        [487],\n",
       "        [876]])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.nonzero(mhot_trigram_banana)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Replacing Booleans with frequencies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a `multihot_freq` function that creates a torch vector of frequencies from a dictionary of indices and frequencies. You will pass the size of the vector as an argument. All the indices in the dictionary will be set to the dictionary values (the relative frequencies) and the rest will be set to 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code\n",
    "def multihot_freq(idx_freq, max):\n",
    "    feat_vector = torch.zeros(max)\n",
    "    for idx,freq in idx_freq.items():\n",
    "        feat_vector[idx] = freq\n",
    "    return feat_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1667, 0.0000,\n",
       "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.5000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.0000, 0.0000, 0.0000, 0.3333, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freq_char_banana = multihot_freq(freqs_banana[0], MAX_CHARS)\n",
    "freq_char_banana"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 25, 234, 310]])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.nonzero(freq_char_banana).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1667, 0.5000, 0.3333]])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freq_char_banana[torch.nonzero(freq_char_banana)].T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating $X$ and $\\mathbf{y}$ tensors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create a function to read the files and return the language and the sentence. We create the $X$ and $\\mathbf{y}$ tensors from them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_sent_lang(file):\n",
    "    with open(file, encoding='utf8', errors='ignore') as f:\n",
    "        for line in f:\n",
    "            row = line.strip()\n",
    "            lang_tuple = tuple(row.split('\\t'))\n",
    "            yield lang_tuple[2], lang_tuple[1]   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Call the read_sent_lang function with the FILE_TRAIN and print the first 10 sentence and language pairs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Приходь до мене.', 'ukr')\n",
      "('Am încercat să-i spun asta, dar nu a vrut să mă asculte.', 'ron')\n",
      "('شیر سرشار از کلسیم نیز هست.', 'pes')\n",
      "('Labai ačiū! Aš tiesiog neturiu žodžių, kaip išreikšti dėkingumą.', 'lit')\n",
      "('Malayalam es un palindromo.', 'ina')\n",
      "('Waar kan ik ticketten kopen voor het theater?', 'nld')\n",
      "('Papiamento kaj la kaboverda kreola havas parencecon.', 'epo')\n",
      "('Vào những ngày trời quang mây tạnh, bạn có thể nhìn thấy núi Phú Sĩ từ xa.', 'vie')\n",
      "('Ne visi žmonės yra pikti velniai.', 'lit')\n",
      "('Tom non lo può fare per Mary.', 'ita')\n",
      "('Έμαθα πολλά από σένα.', 'ell')\n",
      "('我们大概去了，不过要看天气怎么样再决定。', 'cmn')\n",
      "('Hän kirjaili omat nimikirjaimensa valkoiseen nenäliinaan.', 'fin')\n",
      "('Wa somi wa kipolishi wana fanya utafiti mu Africa.', 'swc')\n",
      "(\"waq tuQ 'e' par be'Hom Qup.\", 'tlh')\n",
      "('Не знам какво друго има за обсъждане.', 'bul')\n",
      "('יש לכם פתגם דומה ביפנית?', 'heb')\n",
      "('Kunnen we iets regelen?', 'nld')\n",
      "('Filmen er blevet lækket.', 'dan')\n",
      "('这是839号房间。', 'cmn')\n",
      "('ספר לי משהו שאינני יודע.', 'heb')\n",
      "('Tio kostas tre multe.', 'epo')\n",
      "('Он очень удивился.', 'rus')\n",
      "('Obrigado de antemão pela ajuda.', 'por')\n",
      "('Капітулюйте!', 'ukr')\n",
      "('Jis atsisakė gyvūną užmušti.', 'lit')\n",
      "('Estne therotrophium in hortis publicis?', 'lat')\n",
      "('Dieser Knopf ist locker.', 'deu')\n",
      "('她对自己的才能很自豪。', 'cmn')\n",
      "('अल्जेरियात मला एकटं सोडून जाऊ नकोस.', 'mar')\n"
     ]
    }
   ],
   "source": [
    "# Write your code here\n",
    "# Hint read_sent_lang(...) is an iterator, you can convert it to a list with list(read_sent_l\n",
    "data_list = list(read_sent_lang(FILE_TRAIN))\n",
    "\n",
    "for i in range(30):\n",
    "    print(data_list[i])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code below creates a $X$ and $\\mathbf{y}$ tensors. Note that $X$ is a matrix and $\\mathbf{y}$, a vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_Xy(file, multihot_func, lang2idx):\n",
    "    X_l = []\n",
    "    y_symb = []\n",
    "    line_cnt = 0\n",
    "    for sentence, lang in read_sent_lang(file):\n",
    "        line_cnt += 1 #count the number of lines\n",
    "    X = torch.empty((line_cnt, NUM_FEATURES))\n",
    "    for i, (sentence, lang) in tqdm(enumerate(read_sent_lang(file))):\n",
    "        hashes = hash_ngrams(all_ngrams(sentence), MAXES) #produce a list of numbers for each sentence\n",
    "        hash_freq_l = map(rel_freqs, hashes) #map the frequency to represent hash values\n",
    "        x_row_l = []\n",
    "        for hash_freq_dict, max in zip(hash_freq_l, MAXES):\n",
    "            x_row_l += [multihot_func(hash_freq_dict, max)] \n",
    "        X[i, :] = torch.cat(x_row_l, -1) #connect to 1 tensor\n",
    "        y_symb += [lang]\n",
    "    y = torch.LongTensor(list(map(lang2idx.get, y_symb)))\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "31376it [00:23, 1329.46it/s]\n",
      "3922it [00:02, 1377.25it/s]\n",
      "3923it [00:02, 1337.37it/s]\n"
     ]
    }
   ],
   "source": [
    "if REL_FREQ:\n",
    "    X_train, y_train =  create_Xy(FILE_TRAIN, multihot_freq, lang2idx)\n",
    "    X_val, y_val =  create_Xy(FILE_VAL, multihot_freq, lang2idx)\n",
    "    X_test, y_test =  create_Xy(FILE_TEST, multihot_freq, lang2idx)\n",
    "else:\n",
    "    X_train, y_train =  create_Xy(FILE_TRAIN, multihot, lang2idx)\n",
    "    X_val, y_val =  create_Xy(FILE_VAL, multihot, lang2idx)\n",
    "    X_test, y_test =  create_Xy(FILE_TEST, multihot, lang2idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "X_train.size()\n",
    "print(type(X_test))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "        [0.0000, 0.0000, 0.0000,  ..., 0.0185, 0.0000, 0.0000],\n",
       "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "        ...,\n",
       "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]])"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0:10] #Will be mostly zeros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([37, 28, 25, 21, 15, 24,  9, 38, 21, 16])"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building a Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create the classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = X_train.size()[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write two model architectures using `nn.Sequential`. One corresponding to logistic regression and the other with one hidden layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here\n",
    "if HIDDEN_LAYER:\n",
    "    model = nn.Sequential(\n",
    "        nn.Linear(NUM_FEATURES, 20),\n",
    "        nn.Tanh(),\n",
    "        nn.Linear(20, len(lang2idx)),\n",
    "        nn.LogSoftmax(dim=1)\n",
    "    )\n",
    "else:\n",
    "    model = nn.Sequential(\n",
    "        nn.Linear(NUM_FEATURES, len(lang2idx)),\n",
    "        nn.LogSoftmax(dim=1)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=2583, out_features=20, bias=True)\n",
       "  (1): Tanh()\n",
       "  (2): Linear(in_features=20, out_features=39, bias=True)\n",
       "  (3): LogSoftmax(dim=1)\n",
       ")"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We set the loss and the optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()    # cross entropy loss\n",
    "optimizer = torch.optim.NAdam(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the dataset\n",
    "We use a data loader to supply the training loop with batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = TensorDataset(X_train, y_train)\n",
    "val_dataset = TensorDataset(X_val, y_val)\n",
    "dataloader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the classifier\n",
    "We have a classifier. We now train it on the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write the training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [00:36<00:00,  3.64s/it]\n"
     ]
    }
   ],
   "source": [
    "# Write your code here\n",
    "from sklearn.metrics import f1_score\n",
    "loss_train_history = []\n",
    "acc_train_history = []\n",
    "loss_val_history = []\n",
    "acc_val_history = []\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "for epoch in tqdm(range(EPOCHS)):\n",
    "    loss_train = 0\n",
    "    running_loss = 0\n",
    "    running_correct = 0\n",
    "    running_total = 0\n",
    "    for X_batch, y_batch in dataloader:\n",
    "        optimizer.zero_grad()  #reset gradients\n",
    "        outputs = model(X_batch)\n",
    "        loss = criterion(outputs, y_batch) #compute the loss\n",
    "        loss.backward()  #backword pass\n",
    "        optimizer.step()\n",
    "        loss_train += loss.item()\n",
    "\n",
    "        running_loss += loss.item() * X_batch.size(0)\n",
    "        _, preds = torch.max(outputs,1)\n",
    "        running_correct += (preds == y_batch).sum().item()\n",
    "        running_total += y_batch.size(0)\n",
    "        \n",
    "    epoch_train_loss = running_loss/running_total\n",
    "    epoch_train_acc = running_correct/running_total\n",
    "    loss_train_history.append(epoch_train_loss)\n",
    "    acc_train_history.append(epoch_train_acc)\n",
    "\n",
    "    #validation\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    val_correct = 0\n",
    "    val_total = 0\n",
    "    all_preds = []\n",
    "    all_targets = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X_val, y_val in val_dataloader:\n",
    "\n",
    "\n",
    "            outputs = model(X_val)\n",
    "            loss = criterion(outputs, y_val)\n",
    "        \n",
    "            val_loss   += loss.item() * X_val.size(0)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            val_correct += (preds == y_val).sum().item()\n",
    "            val_total   += y_val.size(0)\n",
    "            all_preds.append(preds.cpu())\n",
    "            all_targets.append(y_val.cpu())\n",
    "\n",
    "    y_true = torch.cat(all_targets).numpy()\n",
    "    y_pred = torch.cat(all_preds).numpy()\n",
    "\n",
    "    epoch_val_loss = val_loss / val_total\n",
    "    epoch_val_acc  = val_correct / val_total\n",
    "    loss_val_history.append(epoch_val_loss)\n",
    "    acc_val_history.append(epoch_val_acc)\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We plot the loss and validation accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.00010750213931073684"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "epochs = range(1, len(loss_train_history) + 1)\n",
    "plt.plot(epochs, loss_train_history, 'bo', label='Training loss')\n",
    "plt.title('Training loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "loss_train_history[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ara     0.9730    0.9730    0.9730       111\n",
      "         ber     0.7757    0.7411    0.7580       112\n",
      "         bul     0.8304    0.9394    0.8815        99\n",
      "         ces     0.9444    0.9189    0.9315       111\n",
      "         cmn     0.9767    0.9545    0.9655        88\n",
      "         dan     0.9074    0.9159    0.9116       107\n",
      "         deu     0.9767    0.9767    0.9767        86\n",
      "         ell     1.0000    0.9896    0.9948        96\n",
      "         eng     0.9640    0.9640    0.9640       111\n",
      "         epo     0.9643    0.9474    0.9558       114\n",
      "         fin     0.9551    0.8854    0.9189        96\n",
      "         fra     0.9691    0.9691    0.9691        97\n",
      "         hau     0.9619    0.9619    0.9619       105\n",
      "         heb     1.0000    1.0000    1.0000        76\n",
      "         hun     0.9479    0.9479    0.9479        96\n",
      "         ina     0.8515    0.9556    0.9005        90\n",
      "         ita     0.8919    0.9167    0.9041       108\n",
      "         jpn     0.9906    0.9722    0.9813       108\n",
      "         kab     0.7545    0.7757    0.7650       107\n",
      "         lat     0.8899    0.8818    0.8858       110\n",
      "         lfn     0.8738    0.8911    0.8824       101\n",
      "         lit     0.9485    0.9583    0.9534        96\n",
      "         mar     1.0000    1.0000    1.0000        98\n",
      "         mkd     0.8922    0.8922    0.8922       102\n",
      "         nld     0.9222    0.9121    0.9171        91\n",
      "         pes     0.9712    0.9528    0.9619       106\n",
      "         pol     0.9490    0.9490    0.9490        98\n",
      "         por     0.9167    0.9167    0.9167       108\n",
      "         ron     0.9800    0.9159    0.9469       107\n",
      "         rus     0.9010    0.9192    0.9100        99\n",
      "         spa     0.8692    0.9118    0.8900       102\n",
      "         srp     0.8667    0.8198    0.8426       111\n",
      "         swc     0.8947    0.9884    0.9392        86\n",
      "         swe     0.9059    0.9167    0.9112        84\n",
      "         tlh     1.0000    0.9792    0.9895        96\n",
      "         tok     0.9813    0.9906    0.9859       106\n",
      "         tur     0.9806    0.9528    0.9665       106\n",
      "         ukr     0.9419    0.8617    0.9000        94\n",
      "         vie     0.9903    0.9903    0.9903       103\n",
      "\n",
      "    accuracy                         0.9291      3922\n",
      "   macro avg     0.9310    0.9309    0.9306      3922\n",
      "weighted avg     0.9301    0.9291    0.9292      3922\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_true, y_pred, target_names=langs, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "epochs = range(1, len(acc_val_history) + 1)\n",
    "plt.plot(epochs, acc_val_history, 'bo', label='Validation accuracy')\n",
    "plt.title('Validation accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting the test set\n",
    "Predict the whole test set. Call the resulting vector `y_test_pred`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred =[]\n",
    "with torch.no_grad():\n",
    "    outputs = model(X_test)\n",
    "    _, y_test_pred = torch.max(outputs, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([32,  1, 18, 37, 19, 35, 32, 23, 12, 16])"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_pred[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ara     0.9884    0.9659    0.9770        88\n",
      "         ber     0.6857    0.7347    0.7094        98\n",
      "         bul     0.7458    0.8800    0.8073       100\n",
      "         ces     0.9540    0.9121    0.9326        91\n",
      "         cmn     0.9794    0.9135    0.9453       104\n",
      "         dan     0.9259    0.9009    0.9132       111\n",
      "         deu     0.9468    0.9889    0.9674        90\n",
      "         ell     1.0000    1.0000    1.0000       106\n",
      "         eng     0.9381    0.9381    0.9381        97\n",
      "         epo     0.9341    0.9770    0.9551        87\n",
      "         fin     0.9725    0.9725    0.9725       109\n",
      "         fra     0.9255    0.9457    0.9355        92\n",
      "         hau     0.9588    0.9688    0.9637        96\n",
      "         heb     1.0000    1.0000    1.0000        99\n",
      "         hun     0.9792    0.9495    0.9641        99\n",
      "         ina     0.8879    0.9810    0.9321       105\n",
      "         ita     0.8899    0.9238    0.9065       105\n",
      "         jpn     0.9891    0.9785    0.9838        93\n",
      "         kab     0.7447    0.6796    0.7107       103\n",
      "         lat     0.8953    0.9390    0.9167        82\n",
      "         lfn     0.9070    0.8966    0.9017        87\n",
      "         lit     0.9773    0.9556    0.9663        90\n",
      "         mar     0.9912    0.9912    0.9912       114\n",
      "         mkd     0.8625    0.7419    0.7977        93\n",
      "         nld     0.9500    0.9500    0.9500       100\n",
      "         pes     0.9794    0.9896    0.9845        96\n",
      "         pol     0.9737    0.9823    0.9780       113\n",
      "         por     0.9565    0.9244    0.9402       119\n",
      "         ron     0.9604    0.8818    0.9194       110\n",
      "         rus     0.8750    0.9074    0.8909       108\n",
      "         spa     0.9038    0.8868    0.8952       106\n",
      "         srp     0.8661    0.8151    0.8398       119\n",
      "         swc     0.9490    0.9588    0.9538        97\n",
      "         swe     0.9167    0.9340    0.9252       106\n",
      "         tlh     0.9703    0.9703    0.9703       101\n",
      "         tok     0.9823    1.0000    0.9911       111\n",
      "         tur     0.9551    0.9770    0.9659        87\n",
      "         ukr     0.9244    0.9167    0.9205       120\n",
      "         vie     1.0000    1.0000    1.0000        91\n",
      "\n",
      "    accuracy                         0.9281      3923\n",
      "   macro avg     0.9293    0.9289    0.9285      3923\n",
      "weighted avg     0.9291    0.9281    0.9280      3923\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_test_pred, target_names=langs, digits=4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 85   0   0 ...   0   0   0]\n",
      " [  0  72   1 ...   0   0   0]\n",
      " [  0   0  88 ...   0   0   0]\n",
      " ...\n",
      " [  0   0   0 ...  85   0   0]\n",
      " [  0   0   1 ...   0 110   0]\n",
      " [  0   0   0 ...   0   0  91]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applying the Detector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode(text, multihot_func, MAXES):\n",
    "    hashes = hash_ngrams(all_ngrams(text), MAXES)\n",
    "    hash_freq_l = map(rel_freqs, hashes)\n",
    "    x_row = torch.empty((0,))\n",
    "    for hash_freq_dict, max in zip(hash_freq_l, MAXES):\n",
    "        x_row = torch.hstack((x_row, multihot_func(hash_freq_dict, max)))\n",
    "    return x_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sents = ['Hi guys and girls!',\n",
    "'Hur mår du nu?', \n",
    "'Allt bra idag?', \n",
    "'Salut tout le monde !']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hi guys and girls! deu\n",
      "Hur mår du nu? swe\n",
      "Allt bra idag? swe\n",
      "Salut tout le monde ! fra\n"
     ]
    }
   ],
   "source": [
    "for sent in test_sents:\n",
    "    if REL_FREQ:\n",
    "        row = encode(sent, multihot_freq, MAXES).unsqueeze(0)\n",
    "    else:\n",
    "        row = encode(sent, multihot, MAXES)\n",
    "    print(sent, idx2lang[torch.argmax(model(row), dim=-1).item()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking Values\n",
    "Your instructor used this piece of code to test his program\n",
    "\n",
    "line 30316 of training set: _Stanna!_\n",
    "\n",
    "The extracted values should match the vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{56: 0.14285714285714285,\n",
       "  432: 0.14285714285714285,\n",
       "  234: 0.2857142857142857,\n",
       "  310: 0.2857142857142857,\n",
       "  333: 0.14285714285714285},\n",
       " {766: 0.16666666666666666,\n",
       "  603: 0.16666666666666666,\n",
       "  649: 0.16666666666666666,\n",
       "  870: 0.16666666666666666,\n",
       "  808: 0.16666666666666666,\n",
       "  547: 0.16666666666666666},\n",
       " {900: 0.2, 166: 0.2, 697: 0.2, 821: 0.2, 1017: 0.2}]"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(map(rel_freqs, hash_ngrams(all_ngrams('Stanna!'), MAXES)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  56,  234,  310,  333,  432, 1068, 1124, 1170, 1287, 1329, 1391, 1718,\n",
       "         2249, 2373, 2452, 2569]])"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.nonzero(X_train[30316]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1429, 0.2857, 0.2857, 0.1429, 0.1429, 0.1667, 0.1667, 0.1667, 0.1667,\n",
       "         0.1667, 0.1667, 0.2000, 0.2000, 0.2000, 0.2000, 0.2000]])"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[30316, torch.nonzero(X_train[30316])].T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results\n",
    "\n",
    "You will report your results for the different methods you tried. You are only required to process the small dataset.\n",
    "\n",
    "\n",
    "| Method   |      Corpus      |  Encoding | Macro F1: Val. set| Macro F1: Test set|\n",
    "|----------|:-------------|:------|------:|------:|\n",
    "| Logistic regression |  Small | Booleans |0.9294|0.9281|\n",
    "| Logistic regression |    Large   |   Booleans |xx|xx|\n",
    "| Logistic regression |  Small |    Frequencies |0.9287|0.9285|\n",
    "| Logistic regression |  Large |    Frequencies |xx|xx|\n",
    "| Neural network |  Small | Booleans |0.9299|0.9281|\n",
    "| Neural network |    Large   |   Booleans |xx|xx|\n",
    "| Neural network |  Small |    Frequencies |0.9291|0.9281|\n",
    "| Neural network |  Large |    Frequencies |xx|xx|\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
